{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Baseline Model Training\n",
    "\n",
    "This notebook trains a baseline deep learning model on preprocessed ECG data:\n",
    "1. Loads preprocessed windows and labels from ECG_Preprocessing.ipynb\n",
    "2. Performs patient-level train/validation/test splitting\n",
    "3. Builds and trains a 1D CNN baseline model\n",
    "4. Evaluates performance and saves results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Dependencies and Import Libraries\n",
    "Install TensorFlow/Keras for deep learning and import necessary packages:\n",
    "- **tensorflow/keras**: Deep learning framework\n",
    "- **scikit-learn**: Model evaluation metrics and utilities\n",
    "- **numpy/pandas**: Numerical computing and data manipulation\n",
    "- **matplotlib**: Visualization of training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow scikit-learn matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Configure Paths and Load Preprocessing Artifacts\n",
    "Set up directories and load the data, labels, and metadata generated by ECG_Preprocessing.ipynb:\n",
    "- **X**: Preprocessed ECG windows (N, T, C)\n",
    "- **y**: Integer labels for each window\n",
    "- **df_qc**: QC metrics and pass/fail information\n",
    "- **label_mapping**: Mapping between diagnosis codes and integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Detect if running in Google Colab and mount Drive =====\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    drive = None\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "# ===== Define paths =====\n",
    "if IN_COLAB:\n",
    "    # Case 1: You manually placed the dataset in MyDrive\n",
    "    DATA_PATH = \"/content/drive/MyDrive/DeepLearningECG/data/\"\n",
    "    ARTIFACT_DIR = \"/content/drive/MyDrive/DeepLearningECG/artifacts/\"\n",
    "\n",
    "else:\n",
    "    # Case 3: Local fallback (if running outside Colab)\n",
    "    DATA_PATH = \"../DeepLearningECG/data/\"\n",
    "    ARTIFACT_DIR = \"../DeepLearningECG/artifacts/\"\n",
    "\n",
    "\n",
    "# Path where the WFDB ECG files (.hea/.dat) live.\n",
    "ECG_DIR = os.path.join(DATA_PATH, \"Child_ecg/\")\n",
    "\n",
    "# Output directory for training results\n",
    "RESULTS_DIR = os.path.join(ARTIFACT_DIR, \"training_results\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"ARTIFACT_DIR:\", ARTIFACT_DIR)\n",
    "print(\"ECG_DIR:\", ECG_DIR)\n",
    "print(\"RESULTS_DIR:\", RESULTS_DIR)\n",
    "print(\"Available artifacts:\", os.listdir(ARTIFACT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load Preprocessed Data and Metadata\n",
    "Load the ECG windows, labels, and QC information from the preprocessing step:\n",
    "- **X_windows.npy**: Preprocessed signal windows (shape: N_windows × 5000 × 12)\n",
    "- **y_labels.npy**: Integer labels for each window\n",
    "- **qc_summary.csv**: QC metrics and metadata per ECG record\n",
    "- **label_mapping.json**: Diagnosis code to integer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "X = np.load(os.path.join(ARTIFACT_DIR, \"X_windows.npy\"))\n",
    "y = np.load(os.path.join(ARTIFACT_DIR, \"y_labels.npy\"))\n",
    "df_qc = pd.read_csv(os.path.join(ARTIFACT_DIR, \"qc_summary.csv\"))\n",
    "\n",
    "# Load label mapping\n",
    "with open(os.path.join(ARTIFACT_DIR, \"label_mapping.json\"), \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "\n",
    "label_to_int = label_mapping[\"label_to_int\"]\n",
    "int_to_label = {int(k): v for k, v in label_mapping[\"int_to_label\"].items()}\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"  X: {X.shape} (windows × time_samples × channels)\")\n",
    "print(f\"  y: {y.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label_idx, count in zip(unique, counts):\n",
    "    diagnosis = int_to_label[int(label_idx)]\n",
    "    print(f\"  {diagnosis}: {count} windows ({100*count/len(y):.1f}%)\")\n",
    "print(f\"\\nNumber of unique diagnoses: {len(label_to_int)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Perform Patient-Level Train/Validation/Test Split\n",
    "Split data at the patient level to avoid data leakage:\n",
    "- Extract unique Patient_IDs from QC summary\n",
    "- Split patient IDs (not individual windows) into 60% train, 20% val, 20% test\n",
    "- Group windows by the patient they came from\n",
    "- This ensures no patient appears in multiple sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patient IDs from filenames in df_qc\n",
    "df_qc['Patient_ID'] = df_qc['Filename'].str.split('/').str[1]\n",
    "\n",
    "print(\"Unique patients in QC summary:\", df_qc['Patient_ID'].nunique())\n",
    "print(\"Total records in QC summary:\", len(df_qc))\n",
    "\n",
    "# Get patient ID for each window\n",
    "# Map each window to a patient based on which record it came from\n",
    "window_to_patient = []\n",
    "for idx, row in df_qc.iterrows():\n",
    "    n_windows = row['n_windows'] if pd.notna(row['n_windows']) else 0\n",
    "    window_to_patient.extend([row['Patient_ID']] * int(n_windows))\n",
    "\n",
    "window_to_patient = np.array(window_to_patient)\n",
    "print(f\"Windows mapped to patients: {len(window_to_patient)} (should match X shape[0]: {X.shape[0]})\")\n",
    "\n",
    "# Verify length matches\n",
    "if len(window_to_patient) != X.shape[0]:\n",
    "    print(\"WARNING: Mismatch between windows and patient mapping!\")\n",
    "    print(f\"Expected {X.shape[0]} windows, got {len(window_to_patient)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split Patient IDs and Create Train/Val/Test Sets\n",
    "Stratified split of unique patients to balance label distribution:\n",
    "- **Train**: 60% of patients (≈60% of windows)\n",
    "- **Validation**: 20% of patients (≈20% of windows)\n",
    "- **Test**: 20% of patients (≈20% of windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique patient IDs and their primary labels\n",
    "unique_patients = df_qc['Patient_ID'].unique()\n",
    "patient_labels = []\n",
    "\n",
    "for patient_id in unique_patients:\n",
    "    # Get all records for this patient and use the most common label\n",
    "    patient_records = df_qc[df_qc['Patient_ID'] == patient_id]\n",
    "    labels = patient_records['label_int'].dropna().values\n",
    "    if len(labels) > 0:\n",
    "        # Use most common label for this patient\n",
    "        most_common_label = int(np.bincount(labels.astype(int)).argmax())\n",
    "    else:\n",
    "        most_common_label = -1\n",
    "    patient_labels.append(most_common_label)\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "train_val_patients, test_patients, train_val_labels, test_labels = train_test_split(\n",
    "    unique_patients, patient_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=patient_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 75% train (of train+val), 25% val (of train+val) = 60% train, 20% val overall\n",
    "train_patients, val_patients, train_labels, val_labels = train_test_split(\n",
    "    train_val_patients, train_val_labels,\n",
    "    test_size=0.25,\n",
    "    stratify=train_val_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train patients: {len(train_patients)} ({100*len(train_patients)/len(unique_patients):.1f}%)\")\n",
    "print(f\"Val patients: {len(val_patients)} ({100*len(val_patients)/len(unique_patients):.1f}%)\")\n",
    "print(f\"Test patients: {len(test_patients)} ({100*len(test_patients)/len(unique_patients):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create Window Indices for Each Split\n",
    "Map patient splits back to individual windows:\n",
    "- For each split (train/val/test), collect all window indices belonging to patients in that split\n",
    "- Create corresponding X and y arrays for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets for faster lookup\n",
    "train_patients_set = set(train_patients)\n",
    "val_patients_set = set(val_patients)\n",
    "test_patients_set = set(test_patients)\n",
    "\n",
    "# Get window indices for each split\n",
    "train_idx = np.where(np.isin(window_to_patient, list(train_patients_set)))[0]\n",
    "val_idx = np.where(np.isin(window_to_patient, list(val_patients_set)))[0]\n",
    "test_idx = np.where(np.isin(window_to_patient, list(test_patients_set)))[0]\n",
    "\n",
    "# Create split datasets\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_val, y_val = X[val_idx], y[val_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "\n",
    "# Verify no overlap\n",
    "assert len(set(train_idx) & set(val_idx)) == 0, \"Train/Val overlap detected!\"\n",
    "assert len(set(train_idx) & set(test_idx)) == 0, \"Train/Test overlap detected!\"\n",
    "assert len(set(val_idx) & set(test_idx)) == 0, \"Val/Test overlap detected!\"\n",
    "print(\"\\n✓ No overlap between train/val/test sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Analyze Label Distribution Across Splits\n",
    "Verify that label distribution is balanced across train/validation/test sets:\n",
    "- Show class distribution for each split\n",
    "- Confirm stratification worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_label_distribution(y, split_name, int_to_label):\n",
    "    \"\"\"Print label distribution for a split.\"\"\"\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n{split_name} label distribution:\")\n",
    "    for label_idx, count in zip(unique, counts):\n",
    "        diagnosis = int_to_label[int(label_idx)]\n",
    "        print(f\"  {diagnosis}: {count} ({100*count/len(y):.1f}%)\")\n",
    "\n",
    "analyze_label_distribution(y_train, \"Train\", int_to_label)\n",
    "analyze_label_distribution(y_val, \"Validation\", int_to_label)\n",
    "analyze_label_distribution(y_test, \"Test\", int_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Define Baseline Model Architecture\n",
    "Build a 1D CNN baseline model for ECG classification:\n",
    "- **Input**: Time-series ECG windows (5000 time steps × 12 channels)\n",
    "- **Architecture**: \n",
    "  - Multiple 1D convolution layers (32, 64, 128 filters)\n",
    "  - Max pooling after each conv block\n",
    "  - Dropout for regularization\n",
    "  - Global average pooling\n",
    "  - Dense classification layers\n",
    "- **Output**: Softmax probabilities over diagnosis classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a 1D CNN baseline model for ECG classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple (time_steps, channels)\n",
    "        num_classes: Number of diagnosis classes\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Block 1\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.Conv1D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Global average pooling and dense layers\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and summarize model\n",
    "num_classes = len(label_to_int)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (time_steps, channels)\n",
    "\n",
    "model = create_baseline_model(input_shape, num_classes)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Train Baseline Model\n",
    "Train the model with early stopping and learning rate scheduling:\n",
    "- **Batch size**: 32 windows\n",
    "- **Epochs**: Up to 100 (early stopping if no improvement)\n",
    "- **Callbacks**:\n",
    "  - Early stopping: Stop if validation loss doesn't improve for 10 epochs\n",
    "  - Learning rate reduction: Reduce LR by 50% if plateau for 5 epochs\n",
    "  - Model checkpoint: Save best model based on validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_checkpoint_path = os.path.join(RESULTS_DIR, f\"baseline_model_{timestamp}.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        model_checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "print(\"Training baseline model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model saved to: {model_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Plot Training History\n",
    "Visualize model training progress:\n",
    "- **Left**: Training and validation loss over epochs\n",
    "- **Right**: Training and validation accuracy over epochs\n",
    "- Shows whether model is learning, overfitting, or underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'training_history_{timestamp}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Training history plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Evaluate on Test Set\n",
    "Comprehensive evaluation of model performance on held-out test data:\n",
    "- Overall accuracy\n",
    "- Per-class precision, recall, F1-score\n",
    "- Confusion matrix\n",
    "- ROC-AUC scores (for multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set\n",
    "y_test_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOverall Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Per-Class Metrics:\")\n",
    "print(\"-\"*70)\n",
    "report = classification_report(\n",
    "    y_test, y_test_pred,\n",
    "    target_names=[int_to_label[i] for i in range(num_classes)],\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Validation accuracy for reference\n",
    "y_val_pred_probs = model.predict(X_val, verbose=0)\n",
    "y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nValidation Accuracy (final epoch): {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Visualize Confusion Matrix\n",
    "Display confusion matrix to identify which diagnoses are confused:\n",
    "- Rows: True labels\n",
    "- Columns: Predicted labels\n",
    "- Diagonal elements show correct predictions\n",
    "- Off-diagonal elements show misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Normalize for visualization\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "diagnosis_names = [int_to_label[i] for i in range(num_classes)]\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt='.2%',\n",
    "    cmap='Blues',\n",
    "    xticklabels=diagnosis_names,\n",
    "    yticklabels=diagnosis_names,\n",
    "    cbar_kws={'label': 'Percentage'},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Normalized Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'confusion_matrix_{timestamp}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Save Training Results and Summary\n",
    "Export model, results, and metadata for later analysis:\n",
    "- Save trained model (HDF5 format)\n",
    "- Save training metrics (JSON)\n",
    "- Save test predictions and probabilities (NPZ)\n",
    "- Create summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in different formats\n",
    "model_h5_path = os.path.join(RESULTS_DIR, f\"baseline_model_{timestamp}.h5\")\n",
    "model_keras_path = os.path.join(RESULTS_DIR, f\"baseline_model_{timestamp}.keras\")\n",
    "\n",
    "model.save(model_h5_path)\n",
    "model.save(model_keras_path)\n",
    "print(f\"✓ Model saved to:\")\n",
    "print(f\"  - {model_h5_path}\")\n",
    "print(f\"  - {model_keras_path}\")\n",
    "\n",
    "# Save metrics and results\n",
    "results = {\n",
    "    'timestamp': timestamp,\n",
    "    'model_type': 'Baseline 1D CNN',\n",
    "    'input_shape': list(input_shape),\n",
    "    'num_classes': num_classes,\n",
    "    'num_parameters': int(model.count_params()),\n",
    "    'training_samples': X_train.shape[0],\n",
    "    'validation_samples': X_val.shape[0],\n",
    "    'test_samples': X_test.shape[0],\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'final_train_loss': float(history.history['loss'][-1]),\n",
    "    'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "    'final_train_accuracy': float(history.history['accuracy'][-1]),\n",
    "    'final_val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'label_mapping': label_to_int,\n",
    "}\n",
    "\n",
    "results_json_path = os.path.join(RESULTS_DIR, f\"training_results_{timestamp}.json\")\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"✓ Results saved to: {results_json_path}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_path = os.path.join(RESULTS_DIR, f\"test_predictions_{timestamp}.npz\")\n",
    "np.savez(\n",
    "    predictions_path,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_test_pred,\n",
    "    y_probs=y_test_pred_probs\n",
    ")\n",
    "print(f\"✓ Test predictions saved to: {predictions_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_path = os.path.join(RESULTS_DIR, f\"training_history_{timestamp}.json\")\n",
    "history_dict = {\n",
    "    'loss': [float(x) for x in history.history['loss']],\n",
    "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "    'val_loss': [float(x) for x in history.history['val_loss']],\n",
    "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "}\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "print(f\"✓ Training history saved to: {history_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Create Summary Report\n",
    "Generate a comprehensive summary report of the training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_report = f\"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════════╗\n",
    "║                    BASELINE MODEL TRAINING REPORT                     ║\n",
    "╚═══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "TRAINING CONFIGURATION\n",
    "{'-'*73}\n",
    "Timestamp:              {timestamp}\n",
    "Model Type:             Baseline 1D CNN\n",
    "Input Shape:            {input_shape}\n",
    "Number of Classes:      {num_classes}\n",
    "Total Parameters:       {results['num_parameters']:,}\n",
    "\n",
    "DATA SPLITS\n",
    "{'-'*73}\n",
    "Train Set:              {X_train.shape[0]:,} windows from {len(train_patients)} patients\n",
    "Validation Set:         {X_val.shape[0]:,} windows from {len(val_patients)} patients\n",
    "Test Set:               {X_test.shape[0]:,} windows from {len(test_patients)} patients\n",
    "Total:                  {X_train.shape[0] + X_val.shape[0] + X_test.shape[0]:,} windows\n",
    "\n",
    "TRAINING RESULTS\n",
    "{'-'*73}\n",
    "Total Epochs Trained:   {results['epochs_trained']}\n",
    "Final Train Loss:       {results['final_train_loss']:.6f}\n",
    "Final Train Accuracy:   {results['final_train_accuracy']:.4f}\n",
    "Final Val Loss:         {results['final_val_loss']:.6f}\n",
    "Final Val Accuracy:     {results['final_val_accuracy']:.4f}\n",
    "\n",
    "TEST SET PERFORMANCE\n",
    "{'-'*73}\n",
    "Test Accuracy:          {test_accuracy:.4f}\n",
    "\n",
    "ARTIFACTS SAVED\n",
    "{'-'*73}\n",
    "Model (HDF5):           {model_h5_path}\n",
    "Model (Keras):          {model_keras_path}\n",
    "Results JSON:           {results_json_path}\n",
    "Predictions (NPZ):      {predictions_path}\n",
    "Training History:       {history_path}\n",
    "Confusion Matrix Plot:  {os.path.join(RESULTS_DIR, f'confusion_matrix_{timestamp}.png')}\n",
    "Training History Plot:  {os.path.join(RESULTS_DIR, f'training_history_{timestamp}.png')}\n",
    "Summary Report:         {os.path.join(RESULTS_DIR, f'summary_report_{timestamp}.txt')}\n",
    "\n",
    "{'-'*73}\n",
    "Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(RESULTS_DIR, f\"summary_report_{timestamp}.txt\")\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"\\n✓ Summary report saved to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
